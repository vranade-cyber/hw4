{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Pkg; Pkg.activate(joinpath(@__DIR__,\"..\")); Pkg.instantiate()\n",
    "using TrajectoryOptimization\n",
    "import TrajectoryOptimization: get_times\n",
    "using RobotDynamics\n",
    "import RobotZoo.Acrobot\n",
    "using StaticArrays\n",
    "using SparseArrays\n",
    "using LinearAlgebra\n",
    "using ForwardDiff\n",
    "using OSQP\n",
    "using Plots\n",
    "using TrajOptPlots\n",
    "using Colors\n",
    "using Printf\n",
    "using Test\n",
    "include(\"acrobot.jl\")\n",
    "include(\"utils.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3: Iterative Learning Control (25 pts)\n",
    "In this problem we'll be exploring the use of iterative learning control (ILC) to update our trajectories to work on a \"real\" system with some un-modeled system dynamics. We'll first find an optimalized trajectory using our approximate model, and then refine those trajectories using ILC to achieve the desired behavior. \n",
    "\n",
    "## Dynamics\n",
    "We'll keep things simple by applying this to the \"acrobot\" system, which is just a double pendulum with actuation only at the elbow joint. We'll use the model out of RobotZoo.\n",
    "\n",
    "## Setting up the Optimization problem\n",
    "We'll use TrajectoryOptimization.jl to define our problem. We specify an initial and terminal constraint, a quadratic cost function that penalizes distance from the goal, and bounds on the torques. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamics Model\n",
    "l0 = @SVector [1.0, 1.0]\n",
    "m0 = @SVector [1.0, 1.0]\n",
    "J0 = @SVector [(1.0/12)*m0[1]*l0[1]*l0[1], (1.0/12)*m0[2]*l0[2]*l0[2]]\n",
    "model = Acrobot(l0, m0, J0)\n",
    "n,m = size(model);\n",
    "\n",
    "# Discretization\n",
    "N = 101\n",
    "Tf = 5.\n",
    "h = Tf/(N-1)\n",
    "\n",
    "# Initial and Final Conditions\n",
    "x0 = @SVector [-pi/2, 0, 0, 0]\n",
    "xf = @SVector [pi/2, 0, 0, 0];  # i.e. swing up\n",
    "\n",
    "# Objective\n",
    "Q = 100.0*Diagonal(@SVector ones(n))\n",
    "Qf = 1000.0*Diagonal(@SVector ones(n))\n",
    "R = 1.0*Diagonal(@SVector ones(m))\n",
    "obj = LQRObjective(Q,R,Qf,xf,N);\n",
    "\n",
    "# Constraints\n",
    "conSet = ConstraintList(n,m,N)\n",
    "\n",
    "#   Control bounds\n",
    "u_bnd = 20.0\n",
    "bnd = BoundConstraint(n,m, u_min=-u_bnd, u_max=u_bnd)\n",
    "add_constraint!(conSet, bnd, 1:N-1)\n",
    "\n",
    "#   Goal constraint\n",
    "goal = GoalConstraint(xf)\n",
    "add_constraint!(conSet, goal, N)\n",
    "\n",
    "# Define the problem\n",
    "prob = Problem(model, obj, xf, Tf, x0=x0, constraints=conSet, integration=RK4);\n",
    "\n",
    "# Initial controls\n",
    "U0 = [randn() for k = 1:N-1]\n",
    "initial_controls!(prob, U0)\n",
    "rollout!(prob);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving the Problem\n",
    "We'll make it easy for you and and solve the problem using ALTRO. Run the code below to solve for the optimized trajectory and visualize the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Altro\n",
    "using Random\n",
    "opts = SolverOptions(\n",
    "    iterations=100000,\n",
    "    constraint_tolerance=1e-4,\n",
    "    projected_newton=0,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "Random.seed!(1)\n",
    "U0 = [randn() for k = 1:N-1]\n",
    "initial_controls!(prob, U0)\n",
    "\n",
    "altro = ALTROSolver(prob, opts)\n",
    "set_options!(altro, show_summary=true)\n",
    "solve!(altro);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis = Visualizer()\n",
    "TrajOptPlots.set_mesh!(vis, model)\n",
    "render(vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize!(vis, model, Tf, states(altro))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part (a): Simulate on \"Real\" System (6 pts)\n",
    "Using out optimized trajectory, design a TVLQR control policy to tracking the new system. You'll also implement a basic simulator to test out your controller on the \"real\" system, which is slightly different than our nominal model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK: Calculate the TVLQR gains (3 pts)\n",
    "\n",
    "# Extract reference trajectory\n",
    "Xref = states(altro)\n",
    "Uref = controls(altro)\n",
    "times = get_times(altro)\n",
    "\n",
    "# TODO: Calculate the TVLQR gains\n",
    "n,m,N = size(altro)\n",
    "K = [zeros(m,n) for k = 1:N]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@test P[end] == Qf\n",
    "@test abs((K[1]*(Xref[2] - Xref[1]))[1] + 11.213) < 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK: Implement the following function (3 pts)\n",
    "\"\"\"\n",
    "    rollout(model, K, Xref, Uref, times; [u_bnd, x0])\n",
    "\n",
    "Simulate the system with the TVLQR controller specified by the feedback gains `K` and reference trajectory `Xref`, `Uref`, and `times`.\n",
    "\n",
    "Should clamp the controls to be between `-u_bnd` and `+u_bnd` prior to integrating the system dynamics.\n",
    "\n",
    "For the dynamics integration, use `xâ€² = true_dynamics_rk4(model, x, u, dt)`.\n",
    "\"\"\"\n",
    "function rollout(model::Acrobot, K, Xref, Uref, times; u_bnd=20.0, x0=Xref[1])\n",
    "    n,m = size(model)\n",
    "    N = length(K) + 1\n",
    "    X = [@SVector zeros(n) for k = 1:N]\n",
    "    U = [@SVector zeros(m) for k = 1:N-1]\n",
    "    X[1] = x0\n",
    "    \n",
    "    # TODO: Simulate at the same time step as the reference trajectory\n",
    "    #  TIP: just loop over the indices, instead of time (just to make it easier)\n",
    "    #  TIP: remember to use `true_dynamics_rk4(model, x, u, dt)` to simulate your dynamics!\n",
    "    #  TIP: remember to clamp your controls before sending them to them to the simulator!\n",
    "    \n",
    "    return X, U\n",
    "end\n",
    "Xsim,Usim = rollout(model, K, states(altro), controls(altro), get_times(altro));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@testset \"Part a\" begin\n",
    "    @test norm(Xsim[1] - states(altro)[1]) < 1e-8\n",
    "    @test 1 < norm(Xsim[end] - states(altro)[end]) < 2\n",
    "    @test abs(maximum(norm.(Usim,Inf)) - u_bnd) < 1e-8\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render(vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize with ghost of the reference trajectory\n",
    "visualize!(vis, model, Tf, Xsim, states(altro), colors=[colorant\"blue\", RGBA(0,0,1,0.5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the joint angles\n",
    "plot(states(altro), inds=1:2, label=\"ref\")\n",
    "plot!(Xsim, inds=1:2, color=[1 2], ls=:dash, legend=:topleft, label=\"actual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the controls\n",
    "plot(controls(altro), label=\"ref\")\n",
    "plot!(Usim, label=\"actual\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part (b): ILC (19 pts)\n",
    "With a reference trajectory and closed-loop controller, let's use ILC to modify the feedforward (reference) control inputs to get our \"real\" system to match our expected trajectory. At each iteration of ILC you should solve a QP of the following form:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\text{minimize} &&& \\frac{1}{2} (\\Delta x_N - \\Delta \\bar{x}_N)^T Q_N (\\Delta x_N - \\Delta \\bar{x}_N) \n",
    "+ \\frac{1}{2} \\sum_{k=1}^{N-1} (\\delta x_k - \\delta \\bar{x}_k)^T Q_k (\\delta x_k - \\delta \\bar{x}_k)\n",
    "                             + (\\delta u_k - \\delta \\bar{u}_k)^T R_k (\\delta u_k - \\delta \\bar{u}_k) \\\\\n",
    "\\text{subject to} &&& \\Delta x_{k+1} = A_k \\Delta x_k + B_k \\Delta x_k \\\\\n",
    "                  &&& -\\Delta u_\\text{bnd} \\leq \\Delta u_k \\leq \\Delta u_\\text{bnd}\n",
    "\\end{align}\n",
    "$$\n",
    "where $\\Delta x = x - x_\\text{ref}$, $\\bar{x}_k$ is the trajectory from the real system, and $x_\\text{ref}$, $u_\\text{ref}$ is the reference trajectory. After every iteration, the reference controls $u_\\text{ref}$ are updated using $\\Delta u$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK: Complete the following function\n",
    "#       1. build_qp    (5 pts)\n",
    "#       2. update_qp!  (4 pts)\n",
    "\n",
    "\"\"\"\n",
    "    ILCData\n",
    "\n",
    "Store basic information about the iterative learning control (ILC)\n",
    "problem, including the quadratic cost function matrices, the reference\n",
    "trajectory, and the control bounds.\n",
    "\"\"\"\n",
    "struct ILCData{n,m,T}\n",
    "    Q::Diagonal{T,SVector{n,T}}\n",
    "    R::Diagonal{T,SVector{m,T}}\n",
    "    Qf::Diagonal{T,SVector{n,T}}\n",
    "    Xref::Vector{SVector{n,T}}\n",
    "    Uref::Vector{SVector{m,T}}\n",
    "    times::Vector{T}\n",
    "    u_bnd::T\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    build_qp(data, Xsim, Usim, A,B,K)\n",
    "\n",
    "Build the QP for the ILC problem, using the data for the ILC problem in `data`,\n",
    "the trajectories from the real system `Xsim`, `Usim`, the linearization about\n",
    "the reference trajectory `A`, `B`, and the feedback matrices `K`.\n",
    "\n",
    "TIP: The dynamics constraints should be on the closed-loop system.\n",
    "\"\"\"\n",
    "function build_qp(data::ILCData, Xsim, Usim, A,B,K)\n",
    "    Nh = length(data.Xref)\n",
    "    n,m = size(B[1])\n",
    "    Xref,Uref = data.Xref, data.Uref\n",
    "    \n",
    "    # TODO: Build the QP for ILC\n",
    "    Np = (Nh-1)*(n+m)         # number of primals\n",
    "    Nd = (Nh-1)*n + (Nh-1)*m  #  number of duals\n",
    "    H = spzeros(Np,Np)\n",
    "    q = zeros(Np)\n",
    "    C = spzeros(Nd,Np)\n",
    "    lb = fill(-Inf,Nd)\n",
    "    ub = fill(+Inf,Nd)\n",
    "    \n",
    "    # Build QP\n",
    "    qp = OSQP.Model()\n",
    "    OSQP.setup!(\n",
    "        qp, P=H, q=q, A=C, l=lb, u=ub,\n",
    "        # QP Parameters: feel free to change these, but these values should work fine\n",
    "        eps_abs=1e-6, eps_rel=1e-6, eps_prim_inf = 1.0e-6, eps_dual_inf = 1.0e-6, polish=1, verbose=0\n",
    "    )\n",
    "    return qp\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    update_qp!(qp, data, X, U)\n",
    "\n",
    "Update the ILC QP with the current trajectories `X` and `U` from the real system.\n",
    "\"\"\"\n",
    "function update_qp!(qp::OSQP.Model, data, X, U)\n",
    "    Nh = length(data.Xref)\n",
    "    n,m = length(X[1]), length(U[1])\n",
    "    Qilc, Rilc, Qf = data.Q, data.R, data.Qf\n",
    "    \n",
    "    # TODO: Update the QP with the new data\n",
    "    Np = (Nh-1)*(n+m)\n",
    "    q = zeros(Np)\n",
    "    \n",
    "    OSQP.update_q!(qp, q)\n",
    "    return q\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK: Implement ILC  (10 pts)\n",
    "\"\"\"\n",
    "    run_ilc(altro; [verbose])\n",
    "\n",
    "Run ILC on the output on the problem and optimized trajectory stored in `altro`. \n",
    "Should iterate until improvements in the SSE between the state trajectory of the real \n",
    "system and the nominal trajectory is small (less than `tol`).\n",
    "\"\"\"\n",
    "function run_ilc(altro;\n",
    "        verbose=true,\n",
    "        tol=1e-2\n",
    "    )\n",
    "    # Get nominal trajectory\n",
    "    Xref = states(altro)\n",
    "    Uref = controls(altro);\n",
    "    n,m,Nh = size(altro)\n",
    "    \n",
    "    # Get costs out of solver\n",
    "    Q = get_objective(altro).obj[1].Q\n",
    "    R = get_objective(altro).obj[1].R\n",
    "    Qf = get_objective(altro).obj[end].Q\n",
    "    \n",
    "    # Get bound out of solver\n",
    "    u_bnd = get_constraints(altro).convals[1].con.z_max[end]\n",
    "    \n",
    "    # ILC Cost functions    \n",
    "    Qilc = Diagonal(SA[1.0; 1.0; 1.0; 1.0])\n",
    "    Rilc = Diagonal(SA[0.1])\n",
    "    \n",
    "    # Generate ILC Data\n",
    "    data = ILCData(Qilc,Rilc,Qf, Xref, Uref, get_times(altro), u_bnd);\n",
    "    \n",
    "    # TODO: Use ILC to improve the tracking performance\n",
    "    #  TIP: you'll need to generate A,B,K and using the code from part (a)\n",
    "    #  TIP: compute the first SSE value outside the loop, and compare between subsequent iterations\n",
    "    #  TIP: you should only need to call build_qp once\n",
    "    Xsim = deepcopy(Xref)\n",
    "    Usim = deepcopy(Uref)\n",
    "    \n",
    "    return Xsim,Usim\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xilc,Uilc = run_ilc(altro);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@testset \"Part b\" begin\n",
    "    @test norm(Xilc - Xref) < 2.1\n",
    "    @test 10 < norm(Uilc - Uref) < 20\n",
    "    @test norm(Xilc[end] - Xref[end]) < 0.05\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render(vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the result (reference shown as a ghost)\n",
    "# TIP: solutions will differ slightly, but should both reach the goal position\n",
    "visualize!(vis, model, Tf, Xilc, states(altro), colors=[colorant\"blue\", RGBA(0,0,1,0.5)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
